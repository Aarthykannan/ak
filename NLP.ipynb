{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpceoCHpdPKyeHjPt6ekFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aarthykannan/ak/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EgVF42zYQchc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "kyMW97L-RK8Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/shakespeare.txt'"
      ],
      "metadata": {
        "id": "zEANLrkLRPGZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path,'r').read()"
      ],
      "metadata": {
        "id": "Lh0cZ7QaRVc6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "vfCsy06sRaNR",
        "outputId": "0222eeb5-a3c6-4339-96b6-422db2bf22c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "vocab    # all unique char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3f9IYQkRcI2",
        "outputId": "c041ea5d-91c5-49a4-a561-6cf14321419a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '>',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '|',\n",
              " '}']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMSNlowARi3k",
        "outputId": "f46f2bd9-46e4-4be6-de05-65235b64372f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all char index\n",
        "\n",
        "char_ind = {char:ind for ind,char in enumerate(vocab)}\n",
        "char_ind['h']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cHHsU1IRsz3",
        "outputId": "57fad1e1-a522-4cc1-98ce-a145867eea69"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_char = np.array(vocab)\n",
        "ind_char[80]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eVAWX8y-SAXN",
        "outputId": "1eded049-1902-4cba-d410-ca0f74a36359"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'y'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encod_txt = np.array([char_ind[c] for c in text])\n",
        "encod_txt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bILTecDLSKuz",
        "outputId": "34d9be9e-56d7-47de-fdc5-d957c8c449a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5445609,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "YNIyai6BSsH7",
        "outputId": "bd75f9b7-1e77-4373-b361-0097c526bc40"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encod_txt[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lLSebJESwIJ",
        "outputId": "b5791151-a02e-4976-e304-759b0836f112"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
              "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
              "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
              "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
              "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
              "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
              "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
              "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
              "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
              "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
              "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
              "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
              "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
              "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
              "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
              "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
              "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
              "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
              "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
              "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
              "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
              "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
              "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
              "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
              "        1, 70, 78, 69,  1, 57, 76])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create batches\n",
        "seq_len = 120\n",
        "total_seq = len(text)//(seq_len +1)  # // to get in whole decimal\n",
        "total_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCeTGZ9WSy5c",
        "outputId": "c0bec7b3-42e5-49a2-bdfa-96ddbe40ccab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_data = tf.data.Dataset.from_tensor_slices(encod_txt)"
      ],
      "metadata": {
        "id": "aNJGlfXvTJbJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(char_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da_A8PDFTsBC",
        "outputId": "3fea4ac8-3259-47e0-8caa-6648ab09bca4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = char_data.batch(seq_len+1,drop_remainder = True) # here // other deciaml points remove"
      ],
      "metadata": {
        "id": "uBPWdTkUT8j0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_seq_target(seq):\n",
        "  ip_txt = seq[:-1]\n",
        "  tar_txt = seq[1:]\n",
        "  return ip_txt,tar_txt"
      ],
      "metadata": {
        "id": "h-PEh5QSUNMn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = seq.map(create_seq_target)"
      ],
      "metadata": {
        "id": "iSvogaGUUyCL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ip_txt,tar_txt in datasets.take(1):\n",
        "  print(ip_txt.numpy())\n",
        "  print(''.join(ind_char[ip_txt.numpy()]))\n",
        "  print('/n')\n",
        "  print(tar_txt.numpy())\n",
        "  print(''.join(ind_char[tar_txt.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYC30xIeU51U",
        "outputId": "3a85ff9f-ca1a-4444-d239-553bb1ecd9d6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "/n\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate batch size\n",
        "\n",
        "batch_size = 128\n",
        "buffer_size = 10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder = True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvvNDMHlVftW",
        "outputId": "391a8141-5687-4784-cb1c-0bdbf9b41896"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Z6-VQAWJye",
        "outputId": "eea04da1-190e-4d99-e098-33db97d1748a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 64\n",
        "rnn_neu = 1026"
      ],
      "metadata": {
        "id": "qClRMe4ZWVl9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy as scc\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Embedding,Dense,Dropout,GRU"
      ],
      "metadata": {
        "id": "iEBLBFK9Wclm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_loss(y_true,y_pred):\n",
        "  return scc(y_true,y_pred,from_logits=True)"
      ],
      "metadata": {
        "id": "rF0UOUzdWveM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocab_size,embed_dim,rnn_neu,batch_size = 1):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size,embed_dim,batch_input_shape =[batch_size,None]))\n",
        "  model.add(GRU(rnn_neu,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "  model.add(Dense(vocab_size))\n",
        "  model.compile(optimizer = 'adam',loss='sparse_loss')\n",
        "  return model"
      ],
      "metadata": {
        "id": "xwtccaSJW8_i"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size=vocab_size,embed_dim=embed_dim,rnn_neu=rnn_neu,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "-QDbS_kVYFL0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10_QC_3-YX5C",
        "outputId": "0f62378a-30af-4d2a-bb89-2941a645b9b8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (128, None, 64)           5376      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (128, None, 84)           86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for ip_eg,tar_eg in dataset.take(1):\n",
        "  eg_pred = model(ip_eg)\n",
        "eg_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAFxqBhLYsIg",
        "outputId": "b7951b03-2c6e-470b-9e94-08bb4eec64c5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 120, 84])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eg_pred[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOQyOgBpZJx6",
        "outputId": "aea19983-b9dd-4c1f-eaba-9ebb9a7c77c9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
              "array([[ 0.01624654, -0.00074363,  0.00233665, ..., -0.0023655 ,\n",
              "         0.00060957, -0.01162981],\n",
              "       [ 0.01471808,  0.00164185,  0.00278377, ..., -0.00336357,\n",
              "         0.00140426, -0.01191324],\n",
              "       [ 0.00953329,  0.00136003, -0.00049821, ...,  0.0031175 ,\n",
              "         0.00149064, -0.00693263],\n",
              "       ...,\n",
              "       [-0.00179395,  0.0006824 ,  0.00110862, ...,  0.00733825,\n",
              "         0.00016177, -0.0015899 ],\n",
              "       [ 0.00628918, -0.00060321,  0.00111935, ...,  0.00424478,\n",
              "         0.00024748, -0.00627991],\n",
              "       [ 0.00693843, -0.00303775, -0.00362401, ..., -0.00309264,\n",
              "        -0.00091497, -0.00785   ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ind = tf.random.categorical(eg_pred[0],num_samples=1)\n",
        "sample_ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJC6ZneAZTg6",
        "outputId": "69241638-ea72-4dbc-913b-855e6aeea5a7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[21],\n",
              "       [57],\n",
              "       [73],\n",
              "       [ 4],\n",
              "       [ 2],\n",
              "       [58],\n",
              "       [71],\n",
              "       [72],\n",
              "       [70],\n",
              "       [77],\n",
              "       [11],\n",
              "       [10],\n",
              "       [68],\n",
              "       [ 4],\n",
              "       [ 7],\n",
              "       [60],\n",
              "       [ 9],\n",
              "       [41],\n",
              "       [83],\n",
              "       [18],\n",
              "       [13],\n",
              "       [29],\n",
              "       [54],\n",
              "       [27],\n",
              "       [74],\n",
              "       [75],\n",
              "       [54],\n",
              "       [11],\n",
              "       [75],\n",
              "       [16],\n",
              "       [46],\n",
              "       [12],\n",
              "       [ 7],\n",
              "       [65],\n",
              "       [51],\n",
              "       [55],\n",
              "       [22],\n",
              "       [74],\n",
              "       [ 9],\n",
              "       [80],\n",
              "       [30],\n",
              "       [31],\n",
              "       [ 2],\n",
              "       [12],\n",
              "       [ 5],\n",
              "       [ 5],\n",
              "       [29],\n",
              "       [37],\n",
              "       [38],\n",
              "       [18],\n",
              "       [42],\n",
              "       [11],\n",
              "       [82],\n",
              "       [34],\n",
              "       [35],\n",
              "       [45],\n",
              "       [40],\n",
              "       [82],\n",
              "       [37],\n",
              "       [15],\n",
              "       [31],\n",
              "       [10],\n",
              "       [72],\n",
              "       [72],\n",
              "       [18],\n",
              "       [15],\n",
              "       [ 1],\n",
              "       [10],\n",
              "       [29],\n",
              "       [58],\n",
              "       [36],\n",
              "       [44],\n",
              "       [48],\n",
              "       [59],\n",
              "       [63],\n",
              "       [79],\n",
              "       [78],\n",
              "       [29],\n",
              "       [60],\n",
              "       [79],\n",
              "       [76],\n",
              "       [ 4],\n",
              "       [80],\n",
              "       [28],\n",
              "       [34],\n",
              "       [13],\n",
              "       [79],\n",
              "       [34],\n",
              "       [ 7],\n",
              "       [ 5],\n",
              "       [30],\n",
              "       [17],\n",
              "       [39],\n",
              "       [26],\n",
              "       [ 2],\n",
              "       [83],\n",
              "       [36],\n",
              "       [41],\n",
              "       [59],\n",
              "       [61],\n",
              "       [74],\n",
              "       [ 4],\n",
              "       [83],\n",
              "       [28],\n",
              "       [63],\n",
              "       [34],\n",
              "       [68],\n",
              "       [35],\n",
              "       [ 7],\n",
              "       [60],\n",
              "       [20],\n",
              "       [ 7],\n",
              "       [59],\n",
              "       [59],\n",
              "       [35],\n",
              "       [ 1],\n",
              "       [60],\n",
              "       [19],\n",
              "       [61],\n",
              "       [31]])>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ind = tf.squeeze(sample_ind,axis=1).numpy()\n",
        "sample_ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAhTHNstZeVZ",
        "outputId": "ff3ff027-8149-41bb-a468-d1cc34e1ae26"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21, 57, 73,  4,  2, 58, 71, 72, 70, 77, 11, 10, 68,  4,  7, 60,  9,\n",
              "       41, 83, 18, 13, 29, 54, 27, 74, 75, 54, 11, 75, 16, 46, 12,  7, 65,\n",
              "       51, 55, 22, 74,  9, 80, 30, 31,  2, 12,  5,  5, 29, 37, 38, 18, 42,\n",
              "       11, 82, 34, 35, 45, 40, 82, 37, 15, 31, 10, 72, 72, 18, 15,  1, 10,\n",
              "       29, 58, 36, 44, 48, 59, 63, 79, 78, 29, 60, 79, 76,  4, 80, 28, 34,\n",
              "       13, 79, 34,  7,  5, 30, 17, 39, 26,  2, 83, 36, 41, 59, 61, 74,  4,\n",
              "       83, 28, 63, 34, 68, 35,  7, 60, 20,  7, 59, 59, 35,  1, 60, 19, 61,\n",
              "       31])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_char[sample_ind]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxxDN3PsZlg2",
        "outputId": "fe9d3d53-1f9c-4b07-d8f5-10b8898ad983"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([':', 'b', 'r', '&', '!', 'c', 'p', 'q', 'o', 'v', '0', '.', 'm',\n",
              "       '&', ')', 'e', '-', 'P', '}', '7', '2', 'D', '_', 'B', 's', 't',\n",
              "       '_', '0', 't', '5', 'U', '1', ')', 'j', 'Z', '`', ';', 's', '-',\n",
              "       'y', 'E', 'F', '!', '1', \"'\", \"'\", 'D', 'L', 'M', '7', 'Q', '0',\n",
              "       '|', 'I', 'J', 'T', 'O', '|', 'L', '4', 'F', '.', 'q', 'q', '7',\n",
              "       '4', ' ', '.', 'D', 'c', 'K', 'S', 'W', 'd', 'h', 'x', 'w', 'D',\n",
              "       'e', 'x', 'u', '&', 'y', 'C', 'I', '2', 'x', 'I', ')', \"'\", 'E',\n",
              "       '6', 'N', 'A', '!', '}', 'K', 'P', 'd', 'f', 's', '&', '}', 'C',\n",
              "       'h', 'I', 'm', 'J', ')', 'e', '9', ')', 'd', 'd', 'J', ' ', 'e',\n",
              "       '8', 'f', 'F'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' epochs = 30\n",
        "    model.fit(dataset,epochs=epochs)'''\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-7PNIE4GZqJo",
        "outputId": "66e57404-efd7-4213-8baf-4c5143823dcc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' epochs = 30\\n    model.fit(dataset,epochs=epochs)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = create_model(vocab_size,embed_dim,rnn_neu,batch_size=1)\n",
        "model.load_weights('shakespeare_gen.h5')\n",
        "model.build(tf.TensorShape([1,None]))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MncIVtwCZ4PV",
        "outputId": "12be329d-a486-4b73-8c60-f2ae4b89be9b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (1, None, 64)             5376      \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (1, None, 84)             86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_txt(model,start_seed,gen_size=500,temp=1.0):\n",
        "\n",
        "  num_gen = gen_size\n",
        "  ip_eval = [char_ind[s] for s in start_seed]  # here flower char char_ind\n",
        "  ip_eval = tf.expand_dims(ip_eval,0)     # to match format shape\n",
        "  txt_gen = []\n",
        "  temperature = temp\n",
        "  model.reset_states()\n",
        "  for i in range(num_gen):\n",
        "    pred = model(ip_eval)  # pred\n",
        "    pred = tf.squeeze(pred,0)   # squeese\n",
        "    pred = pred/temp\n",
        "    pred_id = tf.random.categorical(pred,num_samples=1)[-1,0].numpy()\n",
        "    ip_eval = tf.expand_dims([pred_id],0)\n",
        "    txt_gen.append(ind_char[pred_id])\n",
        "  return (start_seed+''.join(txt_gen))"
      ],
      "metadata": {
        "id": "tIBa0oZGahtl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gen_txt(model,'flower',gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNR8PpAhaymc",
        "outputId": "dfc513c5-8501-470c-d10d-d3b847fb7437"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flower.\n",
            "    What have you done? boot up in place that this should be so bride.\n",
            "  OTHELLO. Leadnow merrily and killingly\n",
            "    Loss on between the pebblesh' that was blameed, a while would have\n",
            "    me\n",
            "    against him, which is not enough of this arm.\n",
            "  PETRUCHIO. What?\n",
            "  MACBETH. Ly pains. I cannot fly the best without\n",
            "    Protectors    With t back, mon Angla.\n",
            "  SECTON. Ay, and my elder Haven within the visitation\n",
            "    To break with this present.\n",
            "  ESCALUS. Why, that's the matter\n",
            "    Of barribonded proof; scorn to my friend;\n",
            "    Which took them to undertake Hero, Scotland.\n",
            "  MENAS. What most that be but grief is still to-morrow?\n",
            "  BOTTOM. Nothing.\n",
            "  JULIA. Abork';\n",
            "    Nor how soon marriage bears more action.\n",
            "    La N, NEDISSION, PRINCE OF YORK DUKE OF YORK\n",
            "  ADAM\n",
            "ENTITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\n",
            "DISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\n",
            "PERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\n",
            "COMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION. My\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3hAL_wk-cS3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}